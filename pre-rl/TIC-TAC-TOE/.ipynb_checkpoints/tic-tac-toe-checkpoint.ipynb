{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "LENGTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(p1, p2, env, draw=False):\n",
    "    current_player = None\n",
    "    while not env.game_over():\n",
    "        #alternate between players\n",
    "        #p1 always start first\n",
    "        if current_player == p1:\n",
    "            current_player = p2\n",
    "        else:\n",
    "            current_player = p1\n",
    " \n",
    "        if draw == 1 and current_player == p1:\n",
    "            env.draw_board()\n",
    "        elif draw == 2 and current_player == p2:\n",
    "            env.draw_board()\n",
    "            \n",
    "        #current_player         \n",
    "        current_player.take_action(env)\n",
    "        \n",
    "        state = env.get_state()\n",
    "        \n",
    "        p1.update_state_history(state)\n",
    "        p2.update_state_history(state)\n",
    "        \n",
    "    if draw:\n",
    "        env.draw_board()\n",
    "    p1.update(env)\n",
    "    p2.update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_hash_and_winner(env, i=0, j=0):\n",
    "    results = []\n",
    "    \n",
    "    for v in (0, env.x, env.o):\n",
    "        env.board[i, j] = v #if empty board it should already be zero.\n",
    "        if j == 2: \n",
    "            #it reached the right side of the board.\n",
    "            #increment i to move downwards and set j=0 to start from left side unless i=2\n",
    "            if i == 2:\n",
    "                #board is full collect results and return \n",
    "                state = env.get_state()\n",
    "                ended = env.game_over(force_recalculate=True)\n",
    "                winner = env.winner\n",
    "                results.append((state, winner, ended))\n",
    "            else:\n",
    "                results+=get_state_hash_and_winner(env, i+1, j=0)\n",
    "        else:\n",
    "            results += get_state_hash_and_winner(env, i, j+1)\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialV_x(env, state_winner_triples):\n",
    "    '''\n",
    "    Initialize state values as follows\n",
    "    if x wins, V(s)=1\n",
    "    if x loses or draws, V(s)=0\n",
    "    otherwise, V(s)=0.5\n",
    "    '''\n",
    "    V = np.zeros(env.num_states)\n",
    "    for state, winner, ended in state_winner_triples:\n",
    "        if ended:\n",
    "            if winner == env.x:\n",
    "                v = 1\n",
    "            else:\n",
    "                v = 0\n",
    "        else:\n",
    "            v = 0.5\n",
    "        V[state] = v\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialV_o(env, state_winner_triples):\n",
    "    '''\n",
    "    Initialize state values as follows\n",
    "    if o wins, V(s)=1\n",
    "    if o loses or draws, V(s)=0\n",
    "    otherwise, V(s)=0.5\n",
    "    '''\n",
    "    V = np.zeros(env.num_states)\n",
    "    for state, winner, ended in state_winner_triples:\n",
    "        if ended:\n",
    "            if winner == env.o:\n",
    "                v = 1\n",
    "            else:\n",
    "                v = 0\n",
    "        else:\n",
    "            v = 0.5\n",
    "        V[state] = v\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((LENGTH, LENGTH))\n",
    "        self.x = -1 #represents the player x on the board\n",
    "        self.o = 1 #represents the player o on the board\n",
    "        self.winner = None\n",
    "        self.ended = False\n",
    "        self.num_states = 3**(LENGTH*LENGTH)\n",
    "        self.opp = {}\n",
    "        self.opp[self.x] = self.o\n",
    "        self.opp[self.o] = self.x\n",
    "        \n",
    "        \n",
    "    def is_empty(self, i, j):\n",
    "        return self.board[i, j] == 0\n",
    "    \n",
    "    def reward(self, symbol):\n",
    "        '''No Reward untill game is over'''\n",
    "        if not self.game_over():\n",
    "            return 0\n",
    "        #if we get here, game is over.\n",
    "        #sym will be self.x or self.o\n",
    "        elif self.winner == symbol:\n",
    "            return 1\n",
    "        elif self.winner == self.opp[symbol]:\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def get_state(self):\n",
    "        #returns the current state represented as int for all prmutation states.\n",
    "        #Number of states wil be 3^|Board Size|, since each state can survive three possible values.\n",
    "        #Some States are not possible, all are X, but we ignore that \n",
    "        #This is like finding an integer representation of base3 number.\n",
    "        \n",
    "        k=0\n",
    "        h=0\n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                if self.board[i, j] == 0:\n",
    "                    v = 0\n",
    "                elif self.board[i, j] == self.x:\n",
    "                    v = 1\n",
    "                elif self.board[i, j] ==  self.o:\n",
    "                    v = 2\n",
    "                h += (3**k) * v\n",
    "                k += 1\n",
    "        return h\n",
    "    \n",
    "    def game_over(self, force_recalculate=False):\n",
    "        \n",
    "        if not force_recalculate and self.ended:\n",
    "            return self.ended\n",
    "\n",
    "        #check rows\n",
    "        for i in range(LENGTH):\n",
    "            for player in (self.x, self.o):\n",
    "                if self.board[i].sum() == player * LENGTH:\n",
    "                    self.winner = player\n",
    "                    self.ended = True\n",
    "                    return True\n",
    "\n",
    "        #check columns \n",
    "        for j in range(LENGTH):\n",
    "            for player in (self.x, self.o):\n",
    "                if self.board[:, j].sum() == player * LENGTH:\n",
    "                    self.winner = player\n",
    "                    self.ended = True\n",
    "                    return True\n",
    "\n",
    "        for player in (self.x, self.o):\n",
    "            #top left -> bottom right\n",
    "            if self.board.trace() == player * LENGTH:\n",
    "                self.winner = player\n",
    "                self.ended = True\n",
    "                return True\n",
    "\n",
    "            #bottom left -> top right\n",
    "            if np.fliplr(self.board).trace() == player * LENGTH:\n",
    "                self.winner = player\n",
    "                self.ended = True\n",
    "                return True\n",
    "  \n",
    "            #check if draw\n",
    "            if np.all((self.board==0) == False):\n",
    "                #winner stays None\n",
    "                self.winner = None\n",
    "                self.ended = True\n",
    "                return True\n",
    "\n",
    "        #game is not over\n",
    "        self.winner = None\n",
    "        return False\n",
    "    \n",
    "    def draw_board(self):\n",
    "        for i in range(LENGTH):\n",
    "            print(\"-\"*15)\n",
    "            for j in range(LENGTH):\n",
    "                print(\"   \", end='')\n",
    "                if self.board[i, j] == self.x:\n",
    "                    print(\"x\", end='')\n",
    "                elif self.board[i, j] == self.o:\n",
    "                    print(\"o\", end='')\n",
    "                else:\n",
    "                    print(\" \", end='')\n",
    "            print(\"\")\n",
    "        print(\"-\"*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, eps=0.1, alpha=0.1):\n",
    "        self.eps = eps #probablity of choosing random action instead of greedy\n",
    "        self.alpha = alpha #learning rate\n",
    "        self.verbose = False\n",
    "        self.state_history = []\n",
    "    \n",
    "    def setV(self, V):\n",
    "        self.V = V\n",
    "        \n",
    "    def set_symbol(self, sym):\n",
    "        self.sym = sym\n",
    "        \n",
    "    def set_verbose(self, v):\n",
    "        self.verbose = v\n",
    "        \n",
    "    def reset_history(self):\n",
    "        self.state_history = []\n",
    "        \n",
    "    def take_action(self, env):\n",
    "        #choosing an action based on epsilon greedy strategy\n",
    "        r = np.random.rand()\n",
    "        best_state = None\n",
    "        \n",
    "        if r < self.eps:\n",
    "            #take a random action:\n",
    "            if self.verbose:\n",
    "                print(\"Taking a Random Action\")\n",
    "            \n",
    "            possible_moves = []\n",
    "            \n",
    "            for i in range(LENGTH):\n",
    "                for j in range(LENGTH):\n",
    "                    if env.is_empty(i, j):\n",
    "                        possible_moves.append((i, j))\n",
    "            idx = np.random.choice(len(possible_moves))\n",
    "            next_move = possible_moves[idx]\n",
    "            \n",
    "        else:\n",
    "            pos2value = {}\n",
    "            next_move = None\n",
    "            best_value = -1\n",
    "            for i in range(LENGTH):\n",
    "                for j in range(LENGTH):\n",
    "                    if env.is_empty(i, j):\n",
    "                        env.board[i, j] = self.sym\n",
    "                        state = env.get_state()\n",
    "                        env.board[i, j] = 0\n",
    "                        pos2value[(i, j)] = self.V[state]\n",
    "                        if self.V[state] > best_value:\n",
    "                            best_value = self.V[state]\n",
    "                            best_state = state\n",
    "                            next_move = (i, j)\n",
    "                            \n",
    "            # if verbose=True, draw the board with the values\n",
    "            \n",
    "            if self.verbose:\n",
    "                print (\"Taking a Greedy Action\")\n",
    "                for i in range(LENGTH):\n",
    "                    print(\"-\"*20)\n",
    "                    for j in range(LENGTH):\n",
    "                        print(\"  \", end='')\n",
    "                        if env.is_empty(i, j):\n",
    "                            print(f\"{round(pos2value[(i,j)], 2)}\", end='')\n",
    "                        else:\n",
    "                            if env.board[i, j] == env.x:\n",
    "                                print(\"x  \", end='')\n",
    "                            elif env.board[i, j] == env.o:\n",
    "                                print(\"o  \", end='')\n",
    "                            else:\n",
    "                                print(\" \", end='')\n",
    "                    print(\"\")\n",
    "                print(\"-\"*20)\n",
    "             \n",
    "        #make the move\n",
    "        env.board[next_move[0], next_move[1]] = self.sym    \n",
    "                \n",
    "    def update_state_history(self, s):\n",
    "        '''cannot put this in take action, because take action only happens once every other iteration for each player.\n",
    "        but state history needs to updated for every iteration\n",
    "        We can pass env and get env.get_state(), but we don't want to do this twice, so we calculate and pass it in.\n",
    "        '''\n",
    "        self.state_history.append(s)\n",
    "        \n",
    "    def update(self, env):\n",
    "        '''Here we want to do this at the end of an episode. which is not true for all the algorithims we study.\n",
    "        We want to backtrack over the states so that :\n",
    "        V(prev_state) = V(prev_state) + alpha * (V(next_state) - V(prev_state))\n",
    "        where V(next_state) =  reward if it is the most current state\n",
    "        '''\n",
    "        \n",
    "        reward = env.reward(self.sym)\n",
    "        target = reward\n",
    "        for prev_state in reversed(self.state_history):\n",
    "            value = self.V[prev_state] + self.alpha *(target - self.V[prev_state])\n",
    "            self.V[prev_state] = value\n",
    "            target = value\n",
    "        self.reset_history()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_symbol(self, sym):\n",
    "        self.sym = sym\n",
    "        \n",
    "    def take_action(self, env):\n",
    "        while True:\n",
    "            #break if we make a legal value\n",
    "            move = input(\"Enter Cordinates i, j for next move: \")\n",
    "            i, j = move.split(',')\n",
    "            i = int(i)\n",
    "            j = int(j)\n",
    "            if env.is_empty(i, j):\n",
    "                env.board[i, j] = self.sym\n",
    "                break\n",
    "    def update(self, env):\n",
    "        pass\n",
    "    \n",
    "    def update_state_history(self, s):\n",
    "        pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "#train the agent\n",
    "p1 = Agent()\n",
    "p2 = Agent()\n",
    "\n",
    "#set initial V for p1 and p2\n",
    "env = Environment()\n",
    "state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "Vx = initialV_x(env, state_winner_triples)\n",
    "Vo = initialV_o(env, state_winner_triples)\n",
    "p1.setV(Vx)\n",
    "p2.setV(Vo)\n",
    "\n",
    "#giving each player their symbol\n",
    "p1.set_symbol(env.x)\n",
    "p2.set_symbol(env.o)\n",
    "\n",
    "T = 10000\n",
    "for t in range(T):\n",
    "    if t%500 == 0:\n",
    "        print(t)\n",
    "    play_game(p1, p2, Environment())\n",
    "\n",
    "#Human playing starts\n",
    "human = Human()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Bharat. For First player enter 1, else enter 2: 1\n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 1,1\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  0.45  0.47  0.49\n",
      "--------------------\n",
      "  0.47  x    0.47\n",
      "--------------------\n",
      "  0.48  0.42  0.48\n",
      "--------------------\n",
      "---------------\n",
      "           o\n",
      "---------------\n",
      "       x    \n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 2,2\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  0.49  0.47  o  \n",
      "--------------------\n",
      "  0.47  x    0.48\n",
      "--------------------\n",
      "  0.41  0.47  x  \n",
      "--------------------\n",
      "---------------\n",
      "   o       o\n",
      "---------------\n",
      "       x    \n",
      "---------------\n",
      "           x\n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 0,1\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  o    x    o  \n",
      "--------------------\n",
      "  0.42  x    0.46\n",
      "--------------------\n",
      "  0.46  0.49  x  \n",
      "--------------------\n",
      "---------------\n",
      "   o   x   o\n",
      "---------------\n",
      "       x    \n",
      "---------------\n",
      "       o   x\n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 1,0\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  o    x    o  \n",
      "--------------------\n",
      "  x    x    0.33\n",
      "--------------------\n",
      "  0.49  o    x  \n",
      "--------------------\n",
      "---------------\n",
      "   o   x   o\n",
      "---------------\n",
      "   x   x    \n",
      "---------------\n",
      "   o   o   x\n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 1,2\n",
      "---------------\n",
      "   o   x   o\n",
      "---------------\n",
      "   x   x   x\n",
      "---------------\n",
      "   o   o   x\n",
      "---------------\n",
      "Play again? [y/n]: y\n",
      "Hi Bharat. For First player enter 1, else enter 2: 2\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  0.51  0.51  0.51\n",
      "--------------------\n",
      "  0.51  0.88  0.84\n",
      "--------------------\n",
      "  0.5  0.51  0.51\n",
      "--------------------\n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "       x    \n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 1,1\n",
      "Enter Cordinates i, j for next move: 1,2\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  0.9  0.52  0.51\n",
      "--------------------\n",
      "  0.5  x    o  \n",
      "--------------------\n",
      "  0.5  0.53  0.51\n",
      "--------------------\n",
      "---------------\n",
      "   x        \n",
      "---------------\n",
      "       x   o\n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 2,1\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  x    0.61  0.5\n",
      "--------------------\n",
      "  0.51  x    o  \n",
      "--------------------\n",
      "  0.5  o    1.0\n",
      "--------------------\n",
      "---------------\n",
      "   x        \n",
      "---------------\n",
      "       x   o\n",
      "---------------\n",
      "       o   x\n",
      "---------------\n",
      "Play again? [y/n]: 1\n",
      "Hi Bharat. For First player enter 1, else enter 2: 2\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  0.51  0.51  0.51\n",
      "--------------------\n",
      "  0.51  0.88  0.84\n",
      "--------------------\n",
      "  0.5  0.51  0.51\n",
      "--------------------\n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "       x    \n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 2,2\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  0.74  0.54  0.52\n",
      "--------------------\n",
      "  0.67  x    0.97\n",
      "--------------------\n",
      "  0.52  0.53  o  \n",
      "--------------------\n",
      "---------------\n",
      "            \n",
      "---------------\n",
      "       x   x\n",
      "---------------\n",
      "           o\n",
      "---------------\n",
      "Enter Cordinates i, j for next move: 0,0\n",
      "Taking a Greedy Action\n",
      "--------------------\n",
      "  o    0.5  0.51\n",
      "--------------------\n",
      "  1.0  x    x  \n",
      "--------------------\n",
      "  0.5  0.5  o  \n",
      "--------------------\n",
      "---------------\n",
      "   o        \n",
      "---------------\n",
      "   x   x   x\n",
      "---------------\n",
      "           o\n",
      "---------------\n",
      "Play again? [y/n]: n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "\n",
    "    player = int(input(\"Hi Bharat. For First player enter 1, else enter 2: \"))\n",
    "\n",
    "    if player == 1:\n",
    "        human.set_symbol(env.x)\n",
    "        p1.set_verbose(False)\n",
    "        p2.set_verbose(True)\n",
    "        play_game(human, p2, Environment(), 1)\n",
    "\n",
    "    if player == 2:\n",
    "        human.set_symbol(env.o)\n",
    "        p1.set_verbose(True)\n",
    "        p2.set_verbose(False)\n",
    "        play_game(p1, human, Environment(), 2)\n",
    "    #We have set agent as player p1 to check whether the agent would select the center as a starting move. \n",
    "    answer = input(\"Play again? [y/n]: \")\n",
    "\n",
    "    if answer == 'n':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
